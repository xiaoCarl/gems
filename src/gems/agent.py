from typing import List, Any

from langchain_core.messages import AIMessage

# ä½¿ç”¨çœŸå®LLM API
from gems.model import call_llm
from gems.prompts import (
    ACTION_SYSTEM_PROMPT,
    VALUE_INVESTMENT_ANSWER_PROMPT,
    PLANNING_SYSTEM_PROMPT,
    STOCK_CONFIRMATION_PROMPT,
    TOOL_ARGS_SYSTEM_PROMPT,
    VALIDATION_SYSTEM_PROMPT,
)
from gems.schemas import Answer, IsDone, OptimizedToolArgs, StockConfirmation, Task, TaskList, ValueInvestmentAnswer
from gems.tools import TOOLS
from langchain_core.tools import BaseTool


class Agent:
    def __init__(self, max_steps: int = 20, max_steps_per_task: int = 5):
        self.max_steps = max_steps            # global safety cap
        self.max_steps_per_task = max_steps_per_task

    # ---------- task planning ----------
    def plan_tasks(self, query: str) -> List[Task]:
        tool_descriptions = "\n".join([f"- {getattr(t, 'name', 'unknown')}: {getattr(t, 'description', 'No description')}" for t in TOOLS])
        prompt = f"""
        Given the user query: "{query}",
        Create a list of tasks to be completed.
        Example: {{"tasks": [{{"id": 1, "description": "some task", "done": false}}]}}
        """
        system_prompt = PLANNING_SYSTEM_PROMPT.format(tools=tool_descriptions)
        try:
            response = call_llm(prompt, system_prompt=system_prompt, output_schema=TaskList)
            tasks = response.tasks
        except Exception as e:
            print(f"Planning failed: {e}")
            tasks = [Task(id=1, description=query, done=False)]
        
        task_dicts = [task.dict() for task in tasks]
        self._log_task_list(task_dicts)
        return tasks

    # ---------- ask LLM what to do ----------
    def ask_for_actions(self, task_desc: str, last_outputs: str = "") -> AIMessage:
        # last_outputs = textual feedback of what we just tried
        prompt = f"""
        We are working on: "{task_desc}".
        Here is a history of tool outputs from the session so far: {last_outputs}

        Based on the task and the outputs, what should be the next step?
        """
        try:
            # Convert TOOLS to BaseTool if needed
            tools_list = [t for t in TOOLS if isinstance(t, BaseTool)]
            return call_llm(prompt, system_prompt=ACTION_SYSTEM_PROMPT, tools=tools_list)
        except Exception as e:
            print(f"ask_for_actions failed: {e}")
            return AIMessage(content="Failed to get actions.")

    # ---------- ask LLM if task is done ----------
    def ask_if_done(self, task_desc: str, recent_results: str) -> bool:
        prompt = f"""
        We were trying to complete the task: "{task_desc}".
        Here is a history of tool outputs from the session so far: {recent_results}

        Is the task done?
        """
        try:
            resp = call_llm(prompt, system_prompt=VALIDATION_SYSTEM_PROMPT, output_schema=IsDone)
            return resp.done
        except:
            return False

    # ---------- optimize tool arguments ----------
    def optimize_tool_args(self, tool_name: str, initial_args: dict, task_desc: str) -> dict:
        """Optimize tool arguments based on task requirements."""
        tool = next((t for t in TOOLS if getattr(t, 'name', None) == tool_name), None)
        if not tool:
            return initial_args
        
        # Get tool schema info
        tool_description = getattr(tool, 'description', 'No description')
        tool_schema = getattr(tool, 'args_schema', None)
        if tool_schema and hasattr(tool_schema, 'schema'):
            tool_schema = tool_schema.schema()
        else:
            tool_schema = {}
        
        prompt = f"""
        Task: "{task_desc}"
        Tool: {tool_name}
        Tool Description: {tool_description}
        Tool Parameters: {tool_schema}
        Initial Arguments: {initial_args}
        
        Review the task and optimize the arguments to ensure all relevant parameters are used correctly.
        Pay special attention to filtering parameters that would help narrow down results to match the task.
        """
        try:
            response = call_llm(prompt, system_prompt=TOOL_ARGS_SYSTEM_PROMPT, output_schema=OptimizedToolArgs)
            # Handle case where LLM returns dict directly instead of OptimizedToolArgs
            if isinstance(response, dict):
                return response if response else initial_args
            return response.arguments
        except Exception as e:
            print(f"Argument optimization failed: {e}, using original args")
            return initial_args

    # ---------- tool execution ----------
    def _execute_tool(self, tool, tool_name: str, inp_args):
        """Execute a tool with progress indication."""
        self._log_task_start(f"æ‰§è¡Œå·¥å…·: {tool_name}")
        result = tool.run(inp_args)
        self._log_task_done(f"å·¥å…·æ‰§è¡Œå®Œæˆ: {tool_name}")
        return result
    
    # ---------- confirm action ----------
    def confirm_action(self, tool: str, input_str: str) -> bool:
        # In production you'd ask the user; here we just log and auto-confirm
        # Risky tools are not implemented in this version.
        return True

    # ---------- main loop ----------
    def run(self, query: str):
        """
        Executes the main agent loop to process a user query.

        This method orchestrates the entire process of understanding a query,
        planning tasks, executing tools to gather information, and synthesizing
        a final answer.

        Args:
            query (str): The user's natural language query.

        Returns:
            str: A comprehensive answer to the user's query.
        """
        # Display the user's query
        self._log_user_query(query)
        
        # Initialize agent state for this run.
        step_count = 0
        last_actions: List[str] = []
        session_outputs: List[str] = []

        # 1. Decompose the user query into a list of tasks.
        tasks = self.plan_tasks(query)

        # If no tasks were created, the query is likely out of scope.
        if not tasks:
            answer = self._generate_answer(query, session_outputs)
            self._log_summary(answer)
            return answer

        # 2. Execute tasks until all are complete or max steps are reached.
        while any(not t.done for t in tasks):
            # Global safety break.
            if step_count >= self.max_steps:
                print("Global max steps reached â€” aborting to avoid runaway loop.")
                break

            # Select the next incomplete task.
            task = next(t for t in tasks if not t.done)
            self._log_task_start(task.description)

            # Loop for a single task, with its own step limit.
            per_task_steps = 0
            task_outputs: List[str] = []
            while per_task_steps < self.max_steps_per_task:
                if step_count >= self.max_steps:
                    print("Global max steps reached â€” stopping.")
                    return

                # Ask the LLM for the next action to take for the current task.
                ai_message = self.ask_for_actions(task.description, last_outputs="\n".join(task_outputs))
                
                # If no tool is called, the task is considered complete.
                if not hasattr(ai_message, 'tool_calls') or not ai_message.tool_calls:
                    task.done = True
                    self._log_task_done(task.description)
                    break

                # Process each tool call returned by the LLM.
                tool_calls = getattr(ai_message, 'tool_calls', [])
                for tool_call in tool_calls:
                    if step_count >= self.max_steps:
                        break

                    tool_name = tool_call["name"]
                    initial_args = tool_call["args"]
                    
                    # Refine tool arguments for better performance.
                    optimized_args = self.optimize_tool_args(tool_name, initial_args, task.description)
                    
                    # Create a signature of the action to be taken.
                    action_sig = f"{tool_name}:{optimized_args}"

                    # Detect and prevent repetitive action loops.
                    last_actions.append(action_sig)
                    if len(last_actions) > 4:
                        last_actions = last_actions[-4:]
                    if len(set(last_actions)) == 1 and len(last_actions) == 4:
                        print("Detected repeating action â€” aborting to avoid loop.")
                        return
                    
                    # Execute the tool.
                    tool_to_run = next((t for t in TOOLS if getattr(t, 'name', None) == tool_name), None)
                    if tool_to_run and self.confirm_action(tool_name, str(optimized_args)):
                        try:
                            result = self._execute_tool(tool_to_run, tool_name, optimized_args)
                            self._log_tool_run(tool_name, f"{result}")
                            output = f"Output of {tool_name} with args {optimized_args}: {result}"
                            session_outputs.append(output)
                            task_outputs.append(output)
                        except Exception as e:
                            print(f"Tool execution failed: {e}")
                            error_output = f"Error from {tool_name} with args {optimized_args}: {e}"
                            session_outputs.append(error_output)
                            task_outputs.append(error_output)
                    else:
                        print(f"Invalid tool: {tool_name}")

                    step_count += 1
                    per_task_steps += 1

                # After a batch of tool calls, check if the task is complete.
                if self.ask_if_done(task.description, "\n".join(task_outputs)):
                    task.done = True
                    self._log_task_done(task.description)
                    break

        # 3. Synthesize the final answer from all collected tool outputs.
        answer = self._generate_answer(query, session_outputs)
        self._log_summary(answer)
        return answer
    
    # ---------- answer generation ----------
    def _generate_answer(self, query: str, session_outputs: list) -> str:
        """Generate the final answer based on collected data."""
        all_results = "\n\n".join(session_outputs) if session_outputs else "No data was collected."
        answer_prompt = f"""
        Original user query: "{query}"
        
        Data and results collected from tools:
        {all_results}
        
        Based on the data above, provide a comprehensive value investment analysis.
        Structure your answer around the two core dimensions of value investing:
        
        1. Good Business (å¥½ç”Ÿæ„)
           - Moat Analysis (æŠ¤åŸæ²³)
           - Management Quality (ç®¡ç†å±‚è´¨é‡) 
           - Business Simplicity (ä¸šåŠ¡ç®€å•æ˜“æ‡‚)
           - Free Cash Flow (è‡ªç”±ç°é‡‘æµ)
        
        2. Good Price (å¥½ä»·æ ¼)
           - PE Valuation (å¸‚ç›ˆç‡ä¼°å€¼)
           - PB Valuation (å¸‚å‡€ç‡ä¼°å€¼) 
           - ROC Metrics (èµ„æœ¬å›æŠ¥ç‡)
           - Margin of Safety (å®‰å…¨è¾¹é™…)
        
        For each dimension, provide:
        - Clear assessment (ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬/è¾ƒå·®)
        - Specific data and analysis
        - Key supporting metrics
        - Risk factors
        
        Conclude with an overall investment recommendation including:
        - Whether it meets "good business + good price" criteria
        - Suggested position sizing
        - Key risks to monitor
        - Long-term holding value assessment
        """
        answer_obj = call_llm(answer_prompt, system_prompt=VALUE_INVESTMENT_ANSWER_PROMPT, output_schema=Answer)
        return answer_obj.answer

    # ---------- simple logging methods ----------
    def _log_user_query(self, query: str):
        """è®°å½•ç”¨æˆ·æŸ¥è¯¢å¹¶ç¡®è®¤è‚¡ç¥¨ä¿¡æ¯"""
        print()
        print(f"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {query}")
        print()
        
        # ç¡®è®¤è‚¡ç¥¨ä¿¡æ¯
        self._confirm_stock_info(query)
    
    def _confirm_stock_info(self, query: str):
        """ç¡®è®¤ç”¨æˆ·è¾“å…¥çš„è‚¡ç¥¨ä¿¡æ¯"""
        confirmation_prompt = f"""
        ç”¨æˆ·æŸ¥è¯¢: "{query}"
        
        è¯·ç¡®è®¤è‚¡ç¥¨ä¿¡æ¯å¹¶è¾“å‡ºç¡®è®¤ä¿¡æ¯ã€‚
        """
        
        try:
            # ä½¿ç”¨LLMç¡®è®¤è‚¡ç¥¨ä¿¡æ¯
            confirmation = call_llm(
                confirmation_prompt, 
                system_prompt=STOCK_CONFIRMATION_PROMPT,
                output_schema=StockConfirmation
            )
            
            # æ˜¾ç¤ºç¡®è®¤ä¿¡æ¯
            print("ğŸ“ˆ è‚¡ç¥¨ç¡®è®¤:")
            print(f"   ğŸ¯ è‚¡ç¥¨: {confirmation.stock_name}")
            print(f"   ğŸ“Š åˆ†æç±»å‹: {confirmation.analysis_type}")
            print(f"   ğŸ” åˆ†æç»´åº¦: {', '.join(confirmation.analysis_dimensions)}")
            
            if confirmation.clarification_needed:
                print(f"   ğŸ’¡ è¯´æ˜: {confirmation.clarification_needed}")
            
            print()
            
        except Exception as e:
            # å¦‚æœç¡®è®¤å¤±è´¥ï¼Œæ˜¾ç¤ºé»˜è®¤ä¿¡æ¯
            print("ğŸ“ˆ è‚¡ç¥¨ç¡®è®¤: è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ä¿¡æ¯")
            print("   ğŸ¯ åˆ†æç±»å‹: ä»·å€¼æŠ•èµ„åˆ†æ")
            print("   ğŸ“Š åˆ†æç»´åº¦: å¥½ç”Ÿæ„ + å¥½ä»·æ ¼")
            print()
    
    def _log_task_list(self, tasks: List[dict]):
        """è®°å½•ä»»åŠ¡åˆ—è¡¨"""
        if not tasks:
            print("æš‚æ— è®¡åˆ’ä»»åŠ¡")
            return
        
        print()
        print("è®¡åˆ’ä»»åŠ¡")
        print("-" * 40)
        for i, task in enumerate(tasks, 1):
            status = "âœ…" if task.get('done', False) else "[]"
            desc = task.get('description', str(task))
            print(f"{status} {i}. {desc}")
        print()
    
    def _log_task_start(self, task_desc: str):
        """è®°å½•ä»»åŠ¡å¼€å§‹"""
        print(f"â†’ å¼€å§‹æ‰§è¡Œ: {task_desc}")
    
    def _log_task_done(self, task_desc: str):
        """è®°å½•ä»»åŠ¡å®Œæˆ"""
        print(f"â†’ å®Œæˆ: {task_desc}")
    
    def _log_tool_run(self, tool: str, result: str = ""):
        """è®°å½•å·¥å…·æ‰§è¡Œ"""
        if result:
            print(f"â†’ å·¥å…·æ‰§è¡Œå®Œæˆ: {tool}")
    
    def _log_summary(self, summary: str):
        """è®°å½•æœ€ç»ˆæ€»ç»“/ç­”æ¡ˆ"""
        # æ£€æµ‹æ˜¯å¦ä¸ºä»·å€¼æŠ•èµ„åˆ†æ
        if any(keyword in summary for keyword in ["å¥½ç”Ÿæ„", "å¥½ä»·æ ¼", "é•¿æœŸæŒæœ‰é£é™©"]):
            print()
            print("ğŸ¯ ä»·å€¼æŠ•èµ„åˆ†ææŠ¥å‘Š")
        else:
            print()
            print("ğŸ“Š åˆ†æç»“æœ")
        print()
        
        # æ ¼å¼åŒ–é•¿æ–‡æœ¬
        formatted_summary = self._format_long_text(summary)
        print(formatted_summary)
        print()
    
    def _format_long_text(self, text: str, max_width: int = 80) -> str:
        """
        æ ¼å¼åŒ–é•¿æ–‡æœ¬ï¼Œç¡®ä¿åœ¨ç»ˆç«¯ä¸­æ­£ç¡®æ˜¾ç¤º
        """
        import re
        
        wrapped_lines = []
        
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = text.split('\n\n')
        
        for paragraph in paragraphs:
            if not paragraph.strip():
                wrapped_lines.append('')
                continue
                
            # æŒ‰è¡Œåˆ†å‰²
            lines = paragraph.split('\n')
            for line in lines:
                if len(line) <= max_width:
                    wrapped_lines.append(line)
                else:
                    # æ™ºèƒ½æ¢è¡Œå¤„ç†
                    current_line = ""
                    words = re.split(r'(\s+)', line)  # æŒ‰ç©ºæ ¼åˆ†å‰²ï¼Œä¿ç•™ç©ºæ ¼
                    
                    for word in words:
                        if not word:
                            continue
                            
                        # å¦‚æœå½“å‰è¡ŒåŠ ä¸Šæ–°å•è¯ä¸è¶…è¿‡æœ€å¤§å®½åº¦
                        if len(current_line) + len(word) <= max_width:
                            current_line += word
                        else:
                            # å½“å‰è¡Œå·²æ»¡ï¼Œå¼€å§‹æ–°è¡Œ
                            if current_line:
                                wrapped_lines.append(current_line.rstrip())
                            current_line = word.lstrip()
                    
                    # æ·»åŠ æœ€åä¸€è¡Œ
                    if current_line:
                        wrapped_lines.append(current_line.rstrip())
            
            # æ®µè½ä¹‹é—´æ·»åŠ ç©ºè¡Œ
            wrapped_lines.append('')
        
        # ç§»é™¤æœ€åçš„ç©ºè¡Œ
        if wrapped_lines and not wrapped_lines[-1]:
            wrapped_lines.pop()
            
        return '\n'.join(wrapped_lines)